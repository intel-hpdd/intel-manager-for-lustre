#!/bin/bash -e

. chroma-manager/tests/framework/utils/defaults.sh
. chroma-manager/tests/framework/utils/selective_auto_pass.sh

set_defaults false
check_for_autopass

# figure out which parallel invocation we might be
WORKSPACE_NUMBER=${WORKSPACE/$HOME\/workspace\/unit-tests@/}
WORKSPACE_NUMBER=${WORKSPACE_NUMBER%%/*}

if [ -n "$WORKSPACE_NUMBER" ]; then
    # use the database created for the workspace number
    ed <<EOF $CHROMA_DIR/chroma-manager/settings.py
/'NAME': 'chroma'/s/',/$WORKSPACE_NUMBER',/
w
q
EOF
fi

# Get the chroma-externals repo as pip is going to need it
scripts/update_chroma-externals.py

# Pip install requirements
cd $CHROMA_DIR/chroma-manager
make requirements
pip install -r requirements.txt

#
# patch behave for https://github.com/behave/behave/issues/63 with https://github.com/jenisys/behave/commit/6fa47d414bf25a53121edeb7caebac4d9d1b5fb4.diff
#
# you'd think that site.getsitepackages() was the right way to do this,
# right?  well, you'd be correct except that life in a virtualenv is not
# quite like life outside of it.
# https://github.com/pypa/virtualenv/issues/355
python_version=$(python -c 'import platform; print ".".join(platform.python_version_tuple()[0:2])')
pushd $WORKSPACE/chroma_test_env/lib/python$python_version/site-packages
patch -R -p1 <<"EOF" || true
diff --git a/behave/model.py b/behave/model.py
index 1183e1b..371c8dd 100644
--- a/behave/model.py
+++ b/behave/model.py
@@ -372,6 +372,8 @@ class Scenario(TagStatement, Replayable)
         self.steps = steps or []
 
         self.background = None
+        self.stderr = None
+        self.stderr = None
 
     def __repr__(self):
         return '<Scenario "%s">' % self.name
EOF
patch -p1 <<"EOF" || true
diff --git a/behave/model.py b/behave/model.py
index 1183e1b..371c8dd 100644
--- a/behave/model.py
+++ b/behave/model.py
@@ -372,6 +372,8 @@ class Scenario(TagStatement, Replayable)
         self.steps = steps or []
 
         self.background = None
+        self.stderr = None
+        self.stdout = None
 
     def __repr__(self):
         return '<Scenario "%s">' % self.name
EOF

popd

if $MEASURE_COVERAGE; then
  python manage.py test --with-xunit --xunit-file=$WORKSPACE/test_reports/chroma-manager-unit-test-results.xml --with-coverage tests/unit/ <<EOC
yes
EOC
  mv .coverage $WORKSPACE/.coverage.chroma_manager_unit_tests

  coverage run --source=. --omit=tests/* -m behave --junit --junit-directory $WORKSPACE/test_reports --format plain tests/feature/cli/features
  mv .coverage $WORKSPACE/.coverage.chroma_manager_behave_unit_tests

  cd ../chroma-agent
  nosetests --with-xunit --xunit-file=$WORKSPACE/test_reports/chroma-agent-unit-test-results.xml --with-coverage
  mv .coverage $WORKSPACE/.coverage.chroma_agent_unit_tests

  cd $WORKSPACE
  coverage combine
  coverage xml --include="$CHROMA_DIR/*" --omit="*junk.py,*/tests/*" --ignore-errors
else
  python manage.py test --with-xunit --xunit-file=$WORKSPACE/test_reports/chroma-manager-unit-test-results.xml tests/unit/ <<EOC
yes
EOC

  behave --junit --junit-directory $WORKSPACE/test_reports --format plain tests/feature/cli/features

  cd ../chroma-agent
  nosetests --with-xunit --xunit-file=$WORKSPACE/test_reports/chroma-agent-unit-test-results.xml
fi

set -e

# Check that all of the expected xml reports are present. (should be 8 when all these tests are working)
if [ $(ls -1 $WORKSPACE/test_reports | wc -l) -lt 8 ]; then
  exit 1
else
  exit 0
fi
